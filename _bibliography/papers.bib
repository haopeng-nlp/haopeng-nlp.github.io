
@misc{zhang2025bestinstructiontuningdatafit,
      title={The Best Instruction-Tuning Data are Those That Fit}, 
      author={Dylan Zhang and Qirun Dai and Hao Peng},
      year={2025},
      eprint={2502.04194},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      pdf={https://arxiv.org/abs/2502.04194}, 
      selected={true},
}

@misc{cui2025processreinforcementimplicitrewards,
      title={Process Reinforcement through Implicit Rewards}, 
      author={Ganqu Cui and Lifan Yuan and Zefan Wang and Hanbin Wang and Wendi Li and Bingxiang He and Yuchen Fan and Tianyu Yu and Qixin Xu and Weize Chen and Jiarui Yuan and Huayu Chen and Kaiyan Zhang and Xingtai Lv and Shuo Wang and Yuan Yao and Xu Han and Hao Peng and Yu Cheng and Zhiyuan Liu and Maosong Sun and Bowen Zhou and Ning Ding},
      year={2025},
      eprint={2502.01456},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      pdf={https://arxiv.org/abs/2502.01456}, 
      selected={true},
}

@misc{dai2025improvinginfluencebasedinstructiontuning,
      title={Improving Influence-based Instruction Tuning Data Selection for Balanced Learning of Diverse Capabilities}, 
      author={Qirun Dai and Dylan Zhang and Jiaqi W. Ma and Hao Peng},
      year={2025},
      eprint={2501.12147},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2501.12147}, 
}

@misc{ge2025llmsvulnerablemaliciousprompts,
      title={LLMs are Vulnerable to Malicious Prompts Disguised as Scientific Language}, 
      author={Yubin Ge and Neeraja Kirtane and Hao Peng and Dilek Hakkani-Tür},
      year={2025},
      eprint={2501.14073},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2501.14073}, 
}


@article{yuan2024freeprocessrewardsprocess,
      title={Free Process Rewards without Process Labels}, 
      author={Lifan Yuan and Wendi Li and Huayu Chen and Ganqu Cui and Ning Ding and Kaiyan Zhang and Bowen Zhou and Zhiyuan Liu and Hao Peng},
      year={2024},
      eprint={2412.01981},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      selected={true},
      pdf={https://arxiv.org/abs/2412.01981}, 
}


@arcticle{lin2024s2attentionhardwareawarecontextsharding,
      title={S2-Attention: Hardware-Aware Context Sharding Among Attention Heads}, 
      author={Xihui Lin and Yunan Zhang and Suyu Ge and Liliang Ren and Barun Patra and Vishrav Chaudhary and Hao Peng and Xia Song},
      year={2024},
      eprint={2407.17678},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      selected={true},
      pdf={https://arxiv.org/abs/2407.17678}, 
}

@article{alnuhait2024factcheckmatepreemptivelydetectingmitigating,
      title={FactCheckmate: Preemptively Detecting and Mitigating Hallucinations in LMs}, 
      author={Deema Alnuhait and Neeraja Kirtane and Muhammad Khalifa and Hao Peng},
      year={2024},
      eprint={2410.02899},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      pdf={https://arxiv.org/abs/2410.02899}
}

@inproceedings{ge2024littlegoeslongway,
      title={A Little Goes a Long Way: Efficient Long Context Training and Inference with Partial Contexts}, 
      author={Suyu Ge and Xihui Lin and Yunan Zhang and Jiawei Han and Hao Peng},
      year={2025},
      booktitle={Proceedings of the International Conference on Learning Representations (ICLR)},
      pdf={https://arxiv.org/abs/2410.01485}, 
      selected={true}
}

@inproceedings{wu2024retrievalheadmechanisticallyexplains,
      title={Retrieval Head Mechanistically Explains Long-Context Factuality}, 
      author={Wenhao Wu and Yizhong Wang and Guangxuan Xiao and Hao Peng and Yao Fu},
      year={2025},
      booktitle={Proceedings of the International Conference on Learning Representations (ICLR)}, 
      selected={true},
      abbr={oral},
      pdf={https://arxiv.org/abs/2404.15574}, 
}



@inproceedings{yuan2024advancing,
      title={Advancing LLM Reasoning Generalists with Preference Trees}, 
      author={Lifan Yuan and Ganqu Cui and Hanbin Wang and Ning Ding and Xingyao Wang and Jia Deng and Boji Shan and Huimin Chen and Ruobing Xie and Yankai Lin and Zhenghao Liu and Bowen Zhou and Hao Peng and Zhiyuan Liu and Maosong Sun},
      year={2025},
      booktitle={Proceedings of the International Conference on Learning Representations (ICLR)}, 
      pdf={https://arxiv.org/abs/2404.02078},
      code={https://github.com/OpenBMB/Eurus}
}

@inproceedings{wang2024openhandsopenplatformai,
      title={OpenHands: An Open Platform for AI Software Developers as Generalist Agents}, 
      author={Xingyao Wang and Boxuan Li and Yufan Song and Frank F. Xu and Xiangru Tang and Mingchen Zhuge and Jiayi Pan and Yueqi Song and Bowen Li and Jaskirat Singh and Hoang H. Tran and Fuqiang Li and Ren Ma and Mingzhang Zheng and Bill Qian and Yanjun Shao and Niklas Muennighoff and Yizhe Zhang and Binyuan Hui and Junyang Lin and Robert Brennan and Hao Peng and Heng Ji and Graham Neubig},
      year={2025},
      booktitle={Proceedings of the International Conference on Learning Representations (ICLR)}, 
      pdf={https://arxiv.org/abs/2407.16741}, 
}

@inproceedings{{wang2024eliminating,
      title={Eliminating Position Bias of Language Models: A Mechanistic Approach}, 
      author={Ziqi Wang and Hanlin Zhang and Xiner Li and Kuan-Hao Huang and Chi Han and Shuiwang Ji and Sham M. Kakade and Hao Peng and Heng Ji},
      year={2025},
      booktitle={Proceedings of the International Conference on Learning Representations (ICLR)}, 
      pdf={https://arxiv.org/abs/2407.01100}, 
      code={https://github.com/wzq016/PINE}
}

@inproceedings{
tian2024scicode,
      title={SciCode: A Research Coding Benchmark Curated by Scientists},
      author={Minyang Tian and Luyu Gao and Dylan Zhang and Xinan Chen and Cunwei Fan and Xuefei Guo and Roland Haas and Pan Ji and Kittithat Krongchon and Yao Li and Shengyan Liu and Di Luo and Yutao Ma and HAO TONG and Kha Trinh and Chenyu Tian and Zihan Wang and Bohao Wu and Shengzhu Yin and Minhui Zhu and Kilian Lieret and Yanxin Lu and Genglin Liu and Yufeng Du and Tianhua Tao and Ofir Press and Jamie Callan and Eliu A Huerta and Hao Peng},
      booktitle={The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
      year={2024},
      selected={true},
      pdf={https://arxiv.org/abs/2407.13168},
      code={https://github.com/scicode-bench/SciCode},
      website={https://scicode-bench.github.io/}
}

@article{chen2024solo,
      title={A Single Transformer for Scalable Vision-Language Modeling}, 
      author={Yangyi Chen and Xingyao Wang and Hao Peng and Heng Ji},
      year={2024},
      journal={Transactions on Machine Learning Research (TMLR)},
      issn={2835-8856},
      pdf={https://arxiv.org/abs/2407.06438},
      code={https://github.com/Yangyi-Chen/SOLO}
}

@article{zhang2024plum,
      title={PLUM: Preference Learning Plus Test Cases Yields Better Code Language Models}, 
      author={Dylan Zhang and Shizhe Diao and Xueyan Zou and Hao Peng},
      year={2024},
      eprint={2406.06887},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      journal={arXiv preprint},
      pdf={https://arxiv.org/abs/2406.06887}, 
}


@inproceedings{khalifa2024sourceaware,
      title={Source-Aware Training Enables Knowledge Attribution in Language Models}, 
      author={Muhammad Khalifa and David Wadden and Emma Strubell and Honglak Lee and Lu Wang and Iz Beltagy and Hao Peng},
      year={2024},
      booktitle={Proceedings of the Conference on Language Modeling (COLM)},
      pdf={https://arxiv.org/abs/2404.01019}
}

@inproceedings{guan2024language,
      title={Language Models Hallucinate, but May Excel at Fact Verification}, 
      author={Jian Guan and Jesse Dodge and David Wadden and Minlie Huang and Hao Peng},
      year={2024},
      booktitle={Proceedings of the North American Chapter of the Association for Computational Linguistics (NAACL)},
      pdf={https://arxiv.org/abs/2310.14564},
      code={https://github.com/JianGuanTHU/LLMforFV}
}

@inproceedings{han2024lminfinite,
      title={LM-Infinite: Zero-Shot Extreme Length Generalization for Large Language Models}, 
      author={Chi Han and Qifan Wang and Hao Peng and Wenhan Xiong and Yu Chen and Heng Ji and Sinong Wang},
      year={2024},
      booktitle={Proceedings of the North American Chapter of the Association for Computational Linguistics (NAACL)},
      pdf={https://arxiv.org/abs/2308.16137},
      code={https://github.com/Glaciohound/LM-Infinite},
    abbr = {best paper<br>honorable mention}
}


@inproceedings{wang2024codeact,
      title={Executable Code Actions Elicit Better LLM Agents}, 
      author={Xingyao Wang and Yangyi Chen and Lifan Yuan and Yizhe Zhang and Yunzhu Li and Hao Peng and Heng Ji},
      year={2024},
      booktitle =    {Proceedings of the International Conference on Machine Learning (ICML)},
      pdf={https://arxiv.org/abs/2402.01030},
      code={https://github.com/xingyaoww/code-act},
      website={https://chat.xwang.dev/},
}

@article{fu2024data,
      title={Data Engineering for Scaling Language Models to 128K Context}, 
      author={Yao Fu and Rameswar Panda and Xinyao Niu and Xiang Yue and Hannaneh Hajishirzi and Yoon Kim and Hao Peng},
      year={2024},
      booktitle =    {Proceedings of the International Conference on Machine Learning (ICML)},
      pdf={https://arxiv.org/abs/2402.10171},
      code={https://github.com/FranxYao/Long-Context-Data-Engineering}
}

@article{liu2024examining,
      title={Examining LLMs' Uncertainty Expression Towards Questions Outside Parametric Knowledge}, 
      author={Genglin Liu and Xingyao Wang and Lifan Yuan and Yangyi Chen and Hao Peng},
      year={2024},
      eprint={2311.09731},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      journal={arXiv preprint},
}

@inproceedings{sherborne2024tram,
      title={TRAM: Bridging Trust Regions and Sharpness Aware Minimization}, 
      author={Tom Sherborne and Naomi Saphra and Pradeep Dasigi and Hao Peng},
      year={2024},
      booktitle={Proceedings of the International Conference on Learning Representations (ICLR)},
      pdf={https://arxiv.org/abs/2310.03646},
      code={https://github.com/tomsherborne/tram_optimizer},
      abbr={spotlight}
}

@inproceedings{wang2024mint,
      title={MINT: Evaluating LLMs in Multi-turn Interaction with Tools and Language Feedback}, 
      author={Xingyao Wang and Zihan Wang and Jiateng Liu and Yangyi Chen and Lifan Yuan and Hao Peng and Heng Ji},
      year={2024},
      booktitle={Proceedings of the International Conference on Learning Representations (ICLR)},
      pdf={https://arxiv.org/abs/2309.10691},
      website={https://xingyaoww.github.io/mint-bench/},
      code={https://github.com/xingyaoww/mint-bench},
      data={https://github.com/xingyaoww/mint-bench/blob/main/docs/DATA.md},
}

@inproceedings{yuan2023craft,
      title={CRAFT: Customizing LLMs by Creating and Retrieving from Specialized Toolsets}, 
      author={Lifan Yuan and Yangyi Chen and Xingyao Wang and Yi R. Fung and Hao Peng and Heng Ji},
      year={2024},
      booktitle={Proceedings of the International Conference on Learning Representations (ICLR)},
      pdf={https://arxiv.org/abs/2309.17428},
      code={https://github.com/lifan-yuan/CRAFT}
}


@article{shen2023film,
      title={FiLM: Fill-in Language Models for Any-Order Generation}, 
      author={Tianxiao Shen and Hao Peng and Ruoqi Shen and Yao Fu and Zaid Harchaoui and Yejin Choi},
      year={2023},
      eprint={2310.09930},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      journal={arXiv preprint},
      pdf={https://arxiv.org/abs/2310.09930},
      code={https://github.com/shentianxiao/FiLM}
}

@article{fu2023improving,
      title={Improving Language Model Negotiation with Self-Play and In-Context Learning from AI Feedback}, 
      author={Yao Fu and Hao Peng and Tushar Khot and Mirella Lapata},
      year={2023},
      eprint={2305.10142},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      journal={arXiv preprint},
      pdf={https://arxiv.org/abs/2305.10142},
      code={https://github.com/FranxYao/GPT-Bargaining}
}

@InProceedings{wang2023leti,
      title={LeTI: Learning to Generate from Textual Interactions}, 
      author={Xingyao Wang and Hao Peng and Reyhaneh Jabbarvand and Heng Ji},
      year={2024},
      booktitle={Proceedings of the North American Chapter of the Association for Computational Linguistics (NAACL)},
      pdf={https://arxiv.org/abs/2305.10314},
      code={https://github.com/xingyaoww/LeTI},
}

@article{peng2023efficiency,
      title={Efficiency Pentathlon: A Standardized Arena for Efficiency Evaluation}, 
      author={Hao Peng and Qingqing Cao and Jesse Dodge and Matthew E. Peters and Jared Fernandez and Tom Sherborne and Kyle Lo and Sam Skjonsberg and Emma Strubell and Darrell Plessas and Iz Beltagy and Evan Pete Walsh and Noah A. Smith and Hannaneh Hajishirzi},
      year={2023},
      eprint={2307.09701},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      journal={arXiv preprint},
      pdf={https://arxiv.org/abs/2307.09701},
      code={https://github.com/allenai/efficiency-pentathlon}
}

@article{fu2023chainofthought,
      title={Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance}, 
      author={Yao Fu and Litu Ou and Mingyu Chen and Yuhao Wan and Hao Peng and Tushar Khot},
      year={2023},
      eprint={2305.17306},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      journal={arXiv preprint},
      pdf={https://arxiv.org/abs/2305.17306},
      website={https://github.com/FranxYao/chain-of-thought-hub},
}


@InProceedings{fu2023specializing,
  title = 	 {Specializing Smaller Language Models towards Multi-Step Reasoning},
  author =       {Fu, Yao and Peng, Hao and Ou, Litu and Sabharwal, Ashish and Khot, Tushar},
  booktitle = 	 {Proceedings of the International Conference on Machine Learning (ICML)},
  pages = 	 {10421--10430},
  year = 	 {2023},
  editor = 	 {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume = 	 {202},
  series = 	 {Proceedings of Machine Learning Research},
  publisher =    {PMLR},
  pdf = 	 {https://arxiv.org/abs/2301.12726},
  code = {https://github.com/FranxYao/FlanT5-CoT-Specialization},
  data = {https://drive.google.com/drive/folders/1BOXcUTnEyvQia_ypHcaUnUbLsN4HzqmQ?usp=sharing},
  abbr = {oral}
}

@inproceedings{
fu2023complexitybased,
title={Complexity-Based Prompting for Multi-step Reasoning},
author={Yao Fu and Hao Peng and Ashish Sabharwal and Peter Clark and Tushar Khot},
booktitle={Proceedings of the International Conference on Learning Representations (ICLR)},
year={2023},
pdf={https://arxiv.org/abs/2210.00720},
code={https://github.com/FranxYao/Complexity-Based-Prompting}
}

@article{wu2023transparency,
    title = "Transparency Helps Reveal When Language Models Learn Meaning",
    author = "Wu, Zhaofeng  and
      Merrill, William  and
      Peng, Hao  and
      Beltagy, Iz  and
      Smith, Noah A.",
    journal = "Transactions of the Association for Computational Linguistics (TACL)",
    volume = "11",
    year = "2023",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    doi = "10.1162/tacl_a_00565",
    pages = "617--634",
    pdf={https://arxiv.org/abs/2210.07468},
    code={https://github.com/ZhaofengWu/transparency},
    slides={https://zhaofengwu.github.io/slides/wu2022transparency.pdf},
    poster={https://zhaofengwu.github.io/posters/wu2022transparency.pdf}
}

@inproceedings{hassid-etal-2022-much,
    title = "How Much Does Attention Actually Attend? Questioning the Importance of Attention in Pretrained Transformers",
    author = "Hassid, Michael  and
      Peng, Hao  and
      Rotem, Daniel  and
      Kasai, Jungo  and
      Montero, Ivan  and
      Smith, Noah A.  and
      Schwartz, Roy",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2022",
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    pdf = "https://arxiv.org/abs/2211.03495",
    doi = "10.18653/v1/2022.findings-emnlp.101",
    pages = "1403--1416",
}

@inproceedings{wu-etal-2022-modeling,
    title = "Modeling Context With Linear Attention for Scalable Document-Level Translation",
    author = "Wu, Zhaofeng  and
      Peng, Hao  and
      Pappas, Nikolaos  and
      Smith, Noah A.",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2022",
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    pdf = "https://arxiv.org/abs/2210.08431",
    doi = "10.18653/v1/2022.findings-emnlp.515",
    pages = "6931--6939"
}

@inproceedings{kasai-etal-2022-twist,
    title = "Twist Decoding: Diverse Generators Guide Each Other",
    author = "Kasai, Jungo  and
      Sakaguchi, Keisuke  and
      Le Bras, Ronan  and
      Peng, Hao  and
      Lu, Ximing  and
      Radev, Dragomir  and
      Choi, Yejin  and
      Smith, Noah A.",
    booktitle = "Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    pdf = "https://arxiv.org/abs/2205.09273",
    doi = "10.18653/v1/2022.emnlp-main.326",
    pages = "4909--4923",
}

@inproceedings{peng-etal-2022-abc,
    title = "{ABC}: Attention with Bounded-memory Control",
    author = "Peng, Hao  and
      Kasai, Jungo  and
      Pappas, Nikolaos  and
      Yogatama, Dani  and
      Wu, Zhaofeng  and
      Kong, Lingpeng  and
      Schwartz, Roy  and
      Smith, Noah A.",
    booktitle = "Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)",
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    pdf = "https://arxiv.org/abs/2110.02488",
    doi = "10.18653/v1/2022.acl-long.515",
    pages = "7469--7483"
}

@inproceedings{ross-etal-2022-tailor,
    title = "Tailor: Generating and Perturbing Text with Semantic Controls",
    author = "Ross, Alexis  and
      Wu, Tongshuang  and
      Peng, Hao  and
      Peters, Matthew  and
      Gardner, Matt",
    booktitle = "Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)",
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/2022.acl-long.228",
    pages = "3194--3213",
    pdf={https://arxiv.org/abs/2107.07150}
}

@inproceedings{kasai-etal-2021-finetuning,
    title = "Finetuning Pretrained Transformers into {RNN}s",
    author = "Kasai, Jungo  and
      Peng, Hao  and
      Zhang, Yizhe  and
      Yogatama, Dani  and
      Ilharco, Gabriel  and
      Pappas, Nikolaos  and
      Mao, Yi  and
      Chen, Weizhu  and
      Smith, Noah A.",
    booktitle = "In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    pdf = "https://aclanthology.org/2021.emnlp-main.830",
    doi = "10.18653/v1/2021.emnlp-main.830",
    pages = "10630--10643"
}

@inproceedings{
peng2021random,
title={Random Feature Attention},
author={Hao Peng and Nikolaos Pappas and Dani Yogatama and Roy Schwartz and Noah Smith and Lingpeng Kong},
booktitle={Proceedings of the International Conference on Learning Representations (ICLR)},
year={2021},
pdf={https://arxiv.org/abs/2103.02143},
abbr={spotlight}
}

@inproceedings{
kasai2021deep,
title={Deep Encoder, Shallow Decoder: Reevaluating Non-autoregressive Machine Translation},
author={Jungo Kasai and Nikolaos Pappas and Hao Peng and James Cross and Noah Smith},
booktitle={Proceedings of the International Conference on Learning Representations (ICLR)},
year={2021},
pdf={https://arxiv.org/abs/2006.10369}
}

@inproceedings{li-etal-2021-contextualized,
    title = "Contextualized Perturbation for Textual Adversarial Attack",
    author = "Li, Dianqi  and
      Zhang, Yizhe  and
      Peng, Hao  and
      Chen, Liqun  and
      Brockett, Chris  and
      Sun, Ming-Ting  and
      Dolan, Bill",
    booktitle = "Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)",
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://arxiv.org/abs/2009.07502",
    doi = "10.18653/v1/2021.naacl-main.400",
    pages = "5053--5069"
}

@article{10.1162/tacl_a_00363,
    author = {Wu, Zhaofeng and Peng, Hao and Smith, Noah A.},
    title = "{Infusing Finetuning with Semantic Dependencies}",
    journal = {Transactions of the Association for Computational Linguistics (TACL)},
    volume = {9},
    pages = {226-242},
    year = {2021},
    issn = {2307-387X},
    doi = {10.1162/tacl_a_00363},
    pdf = {https://arxiv.org/abs/2012.05395},
}

@inproceedings{peng-etal-2020-mixture,
    title = "A Mixture of h - 1 Heads is Better than h Heads",
    author = "Peng, Hao  and
      Schwartz, Roy  and
      Li, Dianqi  and
      Smith, Noah A.",
    booktitle = "Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)",
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    pdf = "https://arxiv.org/abs/2005.06537",
    doi = "10.18653/v1/2020.acl-main.587",
    pages = "6566--6577"
}

@inproceedings{peng-etal-2019-palm,
    title = "{P}a{LM}: A Hybrid Parser and Language Model",
    author = "Peng, Hao  and
      Schwartz, Roy  and
      Smith, Noah A.",
    booktitle = "Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    pdf = "https://aclanthology.org/D19-1376",
    doi = "10.18653/v1/D19-1376",
    pages = "3644--3651"
}

@inproceedings{dodge-etal-2019-rnn,
    title = "{RNN} Architecture Learning with Sparse Regularization",
    author = "Dodge, Jesse  and
      Schwartz, Roy  and
      Peng, Hao  and
      Smith, Noah A.",
    booktitle = "Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    pdf = "https://aclanthology.org/D19-1110",
    doi = "10.18653/v1/D19-1110",
    pages = "1179--1184"
}

@inproceedings{peng-etal-2019-text,
    title = "Text Generation with Exemplar-based Adaptive Decoding",
    author = "Peng, Hao  and
      Parikh, Ankur  and
      Faruqui, Manaal  and
      Dhingra, Bhuwan  and
      Das, Dipanjan",
    booktitle = "Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)",
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    pdf = "https://aclanthology.org/N19-1263",
    doi = "10.18653/v1/N19-1263",
    pages = "2555--2565"
}

@inproceedings{peng-etal-2018-rational,
    title = "Rational Recurrences",
    author = "Peng, Hao  and
      Schwartz, Roy  and
      Thomson, Sam  and
      Smith, Noah A.",
    booktitle = "Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    pdf = "https://aclanthology.org/D18-1152",
    doi = "10.18653/v1/D18-1152",
    pages = "1203--1214"
}

@inproceedings{peng-etal-2018-backpropagating,
    title = "Backpropagating through Structured Argmax using a {SPIGOT}",
    author = "Peng, Hao  and
      Thomson, Sam  and
      Smith, Noah A.",
    booktitle = "Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)",
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    pdf = "https://aclanthology.org/P18-1173",
    doi = "10.18653/v1/P18-1173",
    pages = "1863--1873",
    abbr = {best paper<br>honorable mention}
}

@inproceedings{peng-etal-2018-learning,
    title = "Learning Joint Semantic Parsers from Disjoint Data",
    author = "Peng, Hao  and
      Thomson, Sam  and
      Swayamdipta, Swabha  and
      Smith, Noah A.",
    booktitle = "Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)",
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    pdf = "https://aclanthology.org/N18-1135",
    doi = "10.18653/v1/N18-1135",
    pages = "1492--1502"
}

@inproceedings{10.1145/3178876.3186142,
author = {Tan, Chenhao and Peng, Hao and Smith, Noah A.},
title = {"You Are No Jack Kennedy": On Media Selection of Highlights from Presidential Debates},
year = {2018},
isbn = {9781450356398},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
pdf = {https://arxiv.org/abs/1802.08690},
doi = {10.1145/3178876.3186142},
booktitle = {Proceedings of The Web Conference (WWW)},
pages = {945–954},
numpages = {10},
keywords = {media bias, wording, conversations, presidential debates, quotations},
location = {Lyon, France},
series = {WWW '18}
}

@inproceedings{peng-etal-2017-deep,
    title = "Deep Multitask Learning for Semantic Dependency Parsing",
    author = "Peng, Hao  and
      Thomson, Sam  and
      Smith, Noah A.",
    booktitle = "Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)",
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    pdf = "https://aclanthology.org/P17-1186",
    doi = "10.18653/v1/P17-1186",
    pages = "2037--2048"
}


@InProceedings{pmlr-v48-allamanis16,
  title = 	 {A Convolutional Attention Network for Extreme Summarization of Source Code},
  author = 	 {Allamanis, Miltiadis and Peng, Hao and Sutton, Charles},
  booktitle = 	 {Proceedings of the International Conference on Machine Learning (ICML)},
  pages = 	 {2091--2100},
  year = 	 {2016},
  editor = 	 {Balcan, Maria Florina and Weinberger, Kilian Q.},
  volume = 	 {48},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {New York, New York, USA},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v48/allamanis16.html}
}

@inproceedings{mou-etal-2015-discriminative,
    title = "Discriminative Neural Sentence Modeling by Tree-Based Convolution",
    author = "Mou, Lili  and
      Peng, Hao  and
      Li, Ge  and
      Xu, Yan  and
      Zhang, Lu  and
      Jin, Zhi",
    booktitle = "Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    year = "2015",
    address = "Lisbon, Portugal",
    publisher = "Association for Computational Linguistics",
    pdf = "https://aclanthology.org/D15-1279",
    doi = "10.18653/v1/D15-1279",
    pages = "2315--2325",
}

@inproceedings{xu-etal-2015-classifying,
    title = "Classifying Relations via Long Short Term Memory Networks along Shortest Dependency Paths",
    author = "Xu, Yan  and
      Mou, Lili  and
      Li, Ge  and
      Chen, Yunchuan  and
      Peng, Hao  and
      Jin, Zhi",
    booktitle = "Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    year = "2015",
    address = "Lisbon, Portugal",
    publisher = "Association for Computational Linguistics",
    pdf = "https://aclanthology.org/D15-1206",
    doi = "10.18653/v1/D15-1206",
    pages = "1785--1794",
}