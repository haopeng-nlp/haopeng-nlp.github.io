@article{sherborne2023tram,
      title={TRAM: Bridging Trust Regions and Sharpness Aware Minimization}, 
      author={Tom Sherborne and Naomi Saphra and Pradeep Dasigi and Hao Peng},
      year={2023},
      eprint={2310.03646},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      journal={arXiv preprint},
      pdf={https://arxiv.org/abs/2310.03646},
      code={https://github.com/tomsherborne/tram_optimizer}
}

@article{wang2023mint,
      title={MINT: Evaluating LLMs in Multi-turn Interaction with Tools and Language Feedback}, 
      author={Xingyao Wang and Zihan Wang and Jiateng Liu and Yangyi Chen and Lifan Yuan and Hao Peng and Heng Ji},
      year={2023},
      eprint={2309.10691},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      journal={arXiv preprint},
      pdf={https://arxiv.org/abs/2309.10691},
      website={https://xingyaoww.github.io/mint-bench/},
      code={https://github.com/xingyaoww/mint-bench},
      data={https://github.com/xingyaoww/mint-bench/blob/main/docs/DATA.md}
}

@article{yuan2023craft,
      title={CRAFT: Customizing LLMs by Creating and Retrieving from Specialized Toolsets}, 
      author={Lifan Yuan and Yangyi Chen and Xingyao Wang and Yi R. Fung and Hao Peng and Heng Ji},
      year={2023},
      eprint={2309.17428},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      journal={arXiv preprint},
      pdf={https://arxiv.org/abs/2309.17428},
      code={https://github.com/lifan-yuan/CRAFT},
}

@article{shen2023film,
      title={FiLM: Fill-in Language Models for Any-Order Generation}, 
      author={Tianxiao Shen and Hao Peng and Ruoqi Shen and Yao Fu and Zaid Harchaoui and Yejin Choi},
      year={2023},
      eprint={2310.09930},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      journal={arXiv preprint},
      pdf={https://arxiv.org/abs/2310.09930},
      code={https://github.com/shentianxiao/FiLM},
}

@article{fu2023improving,
      title={Improving Language Model Negotiation with Self-Play and In-Context Learning from AI Feedback}, 
      author={Yao Fu and Hao Peng and Tushar Khot and Mirella Lapata},
      year={2023},
      eprint={2305.10142},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      journal={arXiv preprint},
      pdf={https://arxiv.org/abs/2305.10142},
      code={https://github.com/FranxYao/GPT-Bargaining},
}

@article{wang2023leti,
      title={LeTI: Learning to Generate from Textual Interactions}, 
      author={Xingyao Wang and Hao Peng and Reyhaneh Jabbarvand and Heng Ji},
      year={2023},
      eprint={2305.10314},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      journal={arXiv preprint},
      pdf={https://arxiv.org/abs/2305.10314},
      code={https://github.com/xingyaoww/LeTI},
}

@article{peng2023efficiency,
      title={Efficiency Pentathlon: A Standardized Arena for Efficiency Evaluation}, 
      author={Hao Peng and Qingqing Cao and Jesse Dodge and Matthew E. Peters and Jared Fernandez and Tom Sherborne and Kyle Lo and Sam Skjonsberg and Emma Strubell and Darrell Plessas and Iz Beltagy and Evan Pete Walsh and Noah A. Smith and Hannaneh Hajishirzi},
      year={2023},
      eprint={2307.09701},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      journal={arXiv preprint},
      pdf={https://arxiv.org/abs/2307.09701},
      code={https://github.com/allenai/efficiency-pentathlon},
}

@article{fu2023chainofthought,
      title={Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance}, 
      author={Yao Fu and Litu Ou and Mingyu Chen and Yuhao Wan and Hao Peng and Tushar Khot},
      year={2023},
      eprint={2305.17306},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      journal={arXiv preprint},
      pdf={https://arxiv.org/abs/2305.17306},
      website={https://github.com/FranxYao/chain-of-thought-hub},
}


@InProceedings{fu2023specializing,
  title = 	 {Specializing Smaller Language Models towards Multi-Step Reasoning},
  author =       {Fu, Yao and Peng, Hao and Ou, Litu and Sabharwal, Ashish and Khot, Tushar},
  booktitle = 	 {Proceedings of the International Conference on Machine Learning (ICML)},
  pages = 	 {10421--10430},
  year = 	 {2023},
  editor = 	 {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume = 	 {202},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {23--29 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://arxiv.org/abs/2301.12726},
  code = {https://github.com/FranxYao/FlanT5-CoT-Specialization},
  data = {https://drive.google.com/drive/folders/1BOXcUTnEyvQia_ypHcaUnUbLsN4HzqmQ?usp=sharing}
}

@inproceedings{
fu2023complexitybased,
title={Complexity-Based Prompting for Multi-step Reasoning},
author={Yao Fu and Hao Peng and Ashish Sabharwal and Peter Clark and Tushar Khot},
booktitle={Proceedings of the International Conference on Learning Representations (ICLR)},
year={2023},
pdf={https://arxiv.org/abs/2210.00720},
code={https://github.com/FranxYao/Complexity-Based-Prompting}
}

@article{wu2023transparency,
    title = "Transparency Helps Reveal When Language Models Learn Meaning",
    author = "Wu, Zhaofeng  and
      Merrill, William  and
      Peng, Hao  and
      Beltagy, Iz  and
      Smith, Noah A.",
    journal = "Transactions of the Association for Computational Linguistics (TACL)",
    volume = "11",
    year = "2023",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    doi = "10.1162/tacl_a_00565",
    pages = "617--634",
    pdf={https://arxiv.org/abs/2210.07468},
    code={https://github.com/ZhaofengWu/transparency},
    slides={https://zhaofengwu.github.io/slides/wu2022transparency.pdf},
    poster={https://zhaofengwu.github.io/posters/wu2022transparency.pdf}
}

@inproceedings{hassid-etal-2022-much,
    title = "How Much Does Attention Actually Attend? Questioning the Importance of Attention in Pretrained Transformers",
    author = "Hassid, Michael  and
      Peng, Hao  and
      Rotem, Daniel  and
      Kasai, Jungo  and
      Montero, Ivan  and
      Smith, Noah A.  and
      Schwartz, Roy",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2022",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    pdf = "https://arxiv.org/abs/2211.03495",
    doi = "10.18653/v1/2022.findings-emnlp.101",
    pages = "1403--1416",
}

@inproceedings{wu-etal-2022-modeling,
    title = "Modeling Context With Linear Attention for Scalable Document-Level Translation",
    author = "Wu, Zhaofeng  and
      Peng, Hao  and
      Pappas, Nikolaos  and
      Smith, Noah A.",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2022",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    pdf = "https://arxiv.org/abs/2210.08431",
    doi = "10.18653/v1/2022.findings-emnlp.515",
    pages = "6931--6939"
}

@inproceedings{kasai-etal-2022-twist,
    title = "Twist Decoding: Diverse Generators Guide Each Other",
    author = "Kasai, Jungo  and
      Sakaguchi, Keisuke  and
      Le Bras, Ronan  and
      Peng, Hao  and
      Lu, Ximing  and
      Radev, Dragomir  and
      Choi, Yejin  and
      Smith, Noah A.",
    booktitle = "Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    pdf = "https://arxiv.org/abs/2205.09273",
    doi = "10.18653/v1/2022.emnlp-main.326",
    pages = "4909--4923",
}

@inproceedings{peng-etal-2022-abc,
    title = "{ABC}: Attention with Bounded-memory Control",
    author = "Peng, Hao  and
      Kasai, Jungo  and
      Pappas, Nikolaos  and
      Yogatama, Dani  and
      Wu, Zhaofeng  and
      Kong, Lingpeng  and
      Schwartz, Roy  and
      Smith, Noah A.",
    booktitle = "Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    pdf = "https://arxiv.org/abs/2110.02488",
    doi = "10.18653/v1/2022.acl-long.515",
    pages = "7469--7483"
}

@inproceedings{ross-etal-2022-tailor,
    title = "Tailor: Generating and Perturbing Text with Semantic Controls",
    author = "Ross, Alexis  and
      Wu, Tongshuang  and
      Peng, Hao  and
      Peters, Matthew  and
      Gardner, Matt",
    booktitle = "Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/2022.acl-long.228",
    pages = "3194--3213",
    pdf={https://arxiv.org/abs/2107.07150}
}

@inproceedings{kasai-etal-2021-finetuning,
    title = "Finetuning Pretrained Transformers into {RNN}s",
    author = "Kasai, Jungo  and
      Peng, Hao  and
      Zhang, Yizhe  and
      Yogatama, Dani  and
      Ilharco, Gabriel  and
      Pappas, Nikolaos  and
      Mao, Yi  and
      Chen, Weizhu  and
      Smith, Noah A.",
    booktitle = "In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    pdf = "https://aclanthology.org/2021.emnlp-main.830",
    doi = "10.18653/v1/2021.emnlp-main.830",
    pages = "10630--10643"
}

@inproceedings{
peng2021random,
title={Random Feature Attention},
author={Hao Peng and Nikolaos Pappas and Dani Yogatama and Roy Schwartz and Noah Smith and Lingpeng Kong},
booktitle={Proceedings of the International Conference on Learning Representations (ICLR)},
year={2021},
pdf={https://arxiv.org/abs/2103.02143}
}

@inproceedings{
kasai2021deep,
title={Deep Encoder, Shallow Decoder: Reevaluating Non-autoregressive Machine Translation},
author={Jungo Kasai and Nikolaos Pappas and Hao Peng and James Cross and Noah Smith},
booktitle={Proceedings of the International Conference on Learning Representations (ICLR)},
year={2021},
pdf={https://arxiv.org/abs/2006.10369}
}

@inproceedings{li-etal-2021-contextualized,
    title = "Contextualized Perturbation for Textual Adversarial Attack",
    author = "Li, Dianqi  and
      Zhang, Yizhe  and
      Peng, Hao  and
      Chen, Liqun  and
      Brockett, Chris  and
      Sun, Ming-Ting  and
      Dolan, Bill",
    booktitle = "Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://arxiv.org/abs/2009.07502",
    doi = "10.18653/v1/2021.naacl-main.400",
    pages = "5053--5069"
}

@article{10.1162/tacl_a_00363,
    author = {Wu, Zhaofeng and Peng, Hao and Smith, Noah A.},
    title = "{Infusing Finetuning with Semantic Dependencies}",
    journal = {Transactions of the Association for Computational Linguistics (TACL)},
    volume = {9},
    pages = {226-242},
    year = {2021},
    month = {03},
    issn = {2307-387X},
    doi = {10.1162/tacl_a_00363},
    pdf = {https://arxiv.org/abs/2012.05395},
}

@inproceedings{peng-etal-2020-mixture,
    title = "A Mixture of h - 1 Heads is Better than h Heads",
    author = "Peng, Hao  and
      Schwartz, Roy  and
      Li, Dianqi  and
      Smith, Noah A.",
    booktitle = "Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    pdf = "https://arxiv.org/abs/2005.06537",
    doi = "10.18653/v1/2020.acl-main.587",
    pages = "6566--6577"
}